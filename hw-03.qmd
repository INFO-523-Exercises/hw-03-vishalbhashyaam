---
title: "hw-03.qmd"
author: "VISHAL BHASHYAAM"
format: html
editor: visual
---

# Classification: Basic Concepts and Techniques

## Install packages

Install the required packages used in the chapter:

```{r}

if (!require(pacman))
  install.packages("pacman")

pacman::p_load(tidyverse ,rpart, rpart.plot, caret , lattice, FSelector,
               sampling,pROC)

# I am not installing ml bench because I am using different dataset which does not require mlbench.
```

## Spam E-mail Dataset

I am using the spam e-mail dataset which either requires the tidytuesdayR package or we can read it directly from the github

```{r}
# Reading the dataset directly from github

spam <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2023/2023-08-15/spam.csv')
spamCsv <- spam
```

```{r}
spamCsv |>
  head() |>
  formattable::formattable()
```

```{r}
library(tidyverse)
as_tibble(spamCsv)
```

```{r}
spam |>
  summary() 
  
```

Converting yes/no values into factors(nominal), used to build models.

```{r}
spamCsv <- spamCsv |>
  mutate(across(where(is.logical), factor, levels = c("y", "n"))) |>
  mutate(across(where(is.character), factor))
```

```{r}
summary(spamCsv)
```

## Decision Trees

Recursive Partitioning uses the Gini index to make splitting decisions and early stopping (pre-pruning)

```{r}
library(rpart)
```

## Creating tree with default setting (uses pre-pruning)

```{r}
tree_default <-spamCsv |>
  rpart(yesno ~ ., data = _)

tree_default
```

## Plotting

```{r}
library(rpart.plot)
rpart.plot(tree_default, extra =2)
```

## Creating a Full Tree

```{r}
tree_full <- spamCsv |> 
  rpart(yesno~. , data = _, 
        control = rpart.control(minsplit = 2, cp = 0))
rpart.plot(tree_full, extra = 2, 
           roundint=FALSE,
            box.palette = list("Gy", "Gn", "Bu", "Bn", 
                               "Or", "Rd", "Pu")) # specify 7 colors
```

```{r}
tree_full
```

```{r}
predict(tree_default,spamCsv) |> head()
```

```{r}
pred <- predict(tree_default, spamCsv, type="class")
head(pred)
```

```{r}
confusion_table <- with(spamCsv,table(yesno,pred))
confusion_table
```

```{r}
correct  <- confusion_table |> diag() |> sum()
correct
```

```{r}
error  <- confusion_table |> sum() - correct
error
```

```{r}
accuracy <- correct / (correct + error)
accuracy
```

Use a function for accuracy

```{r}
accuracy <- function(truth, prediction) {
    tbl <- table(truth, prediction)
    sum(diag(tbl))/sum(tbl)
}

accuracy(spamCsv |> pull(yesno), pred)
```

Training error of the full tree

```{r}
accuracy(spamCsv |> pull(yesno), predict(tree_full,spamCsv, type="class"))
```

Get a confusion table with more statistics (using caret)

```{r}
library(caret)
confusionMatrix(data = pred, 
                reference = spamCsv |> pull(yesno))
```

```{r}
spamCsv
```

## Making prediction for New Data

```{r}
my_spamCsv <- tibble(crl.tot = 23,
dollar=0.52,
bang=0.526,
money=0.15,
n000=0.00,
make=0.01,
yesno=NA)
```

```{r}
my_spamCsv<-my_spamCsv |>
  mutate(across(where(is.logical),factor,levels =c("y","n")))
my_spamCsv
```

```{r}
predict(tree_default, my_spamCsv, type = "class")
```

## Model Evaluation with Caret

```{r}
library(caret)
```

```{r}
set.seed(2000)
```

## Holding out Test data

```{r}
inTrain <- createDataPartition(y= spamCsv$yesno, p =.8, list= FALSE)
spamCsv_train <- spamCsv |> slice(inTrain)
```

```{r}
spamCsv_test <- spamCsv |> slice(-inTrain)
```

## Learn a Model and Tune Hyperparameters on the Training Data

```{r}
fit <- spamCsv |>
  train(yesno~.,
        data=_ ,
        method = "rpart",
        control = rpart.control(minsplit = 2),
        trControl = trainControl(method = "cv", number = 10),
        tuneLength = 5)

fit
```

```{r}
rpart.plot(fit$finalModel, extra =2 ,
           box.palette = list("Gy", "Gn", "Bu", "Bn", "Or", "Rd", "Pu"))
```

```{r}
varImp(fit)
```

Here is the variable importance without completing splits.

```{r}
imp <- varImp(fit, compete = FALSE)
imp
```

```{r}
ggplot(imp)
```

## Testing: Confusion Matrix and Confidence Interval for Accuracy

Using the best model on the test data

```{r}
pred <- predict(fit, newdata= spamCsv_test)
pred
```

```{r}
confusionMatrix(data = pred,
                ref = spamCsv_test |> pull(yesno))
```

## Model Comparison

```{r}
train_index <- createFolds(spamCsv_train$yesno, k=10)
```

Building models

```{r}
rpartFit <- spamCsv_train |> 
  train(yesno ~ .,
        data = _,
        method = "rpart",
        tuneLength = 10,
        trControl = trainControl(method = "cv", indexOut = train_index)
  )
```

```{r}
knnFit <- spamCsv_train |> 
  train(yesno ~ .,
        data = _,
        method = "knn",
        preProcess = "scale",
          tuneLength = 10,
          trControl = trainControl(method = "cv", indexOut = train_index)
  )
```

Comparing accuracy over all folds:

```{r}
resamps <- resamples(list(
  CART = rpartFit,
  kNearestNeighbors = knnFit
))

summary(resamps)
```

```{r}
library(lattice)
bwplot(resamps, layout = c(3,1))
```

```{r}
difs <- diff(resamps)
difs
```

```{r}
summary(difs)
```

## Feature Selection and Feature Preparation

```{r}
if(!require(rJava))
  install.packages("rJava",type = "source")
if(!require(RWeka))
  install.packages("RWeka")

```

```{r}
Sys.setenv(JAVA_HOME='~/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home')
```

```{r}
library(FSelector)
```

## Univariate Feature Importance Score

```{r}
weights <-spamCsv |> 
  chi.squared(yesno ~ ., data = _) |>
  as_tibble(rownames = "feature") |>
  arrange(desc(attr_importance))

weights
```

Plotting importance in descending order (using `reorder` to order factor levels used by `ggplot`)

```{r}
ggplot(weights,
       aes(x = attr_importance, y = reorder(feature, attr_importance))) +
  geom_bar(stat = "identity") + 
  xlab("Important Score") +
  ylab("Feature")
```

Getting the best 4 features:

```{r}
subset <- cutoff.k(weights |>
                     column_to_rownames("feature"),4)

subset 
```

Using the best 4 features to build a model (`FSelector` provides `as.simple.formula`)

```{r}
f<- as.simple.formula(subset, "yesno")
f
```

```{r}
m <- spamCsv_train |> rpart(f, data= _)
rpart.plot(m, extra = 2, roundint = FALSE)
```

```{r}
spamCsv |>
  gain.ratio(yesno~. , data= _) |>
  as_tibble(rownames = "feature") |>
  arrange(desc(attr_importance))
```

## Feature Subset Selection

```{r}
spamCsv |>
  cfs(yesno ~ ., data= _)
```

```{r}
evaluator <- function(subset) {
  model <- spamCsv_train |> 
    train(as.simple.formula(subset, "yesno"),
          data = _,
          method = "rpart",
          trControl = trainControl(method = "boot", number = 5),
          tuneLength = 0)
  results <- model$resample$Accuracy
  cat("Trying features:", paste(subset, collapse = " + "), "\n")
  m <- mean(results)
  cat("Accuracy:", round(m, 2), "\n\n")
  m
}
```

Start with all feature (but not the class variable `type`)

```{r}
features <- spamCsv_train |> colnames() |> setdiff("type") 
```

There are other greedy search strategies available but takes a lot of computational time

```{r}
##subset <- backward.search(features, evaluator)
##subset <- forward.search(features, evaluator)
##subset <- best.first.search(features, evaluator)
##subset <- hill.climbing.search(features, evaluator)
##subset
```

## Using Dummy Variable as Factors

Using dummy variable is not possible, because I need to create it, and this dataset contains only categorical dataset which is the prediction for this dataset. I cannot convert any column in as.factor because each value is unique and random values (numerical). Just using money column to implement this technique.

```{r, warning=FALSE}
tree_predator <- spamCsv_train |>
  rpart(money ~ yesno, data= _)

rpart.plot(tree_predator,roundint = FALSE)
```

This code below doesn't make sense because "money" does not a have categorical value and `n` and `y` we cant predict anything with numerical value. just implementing the code for reference.

```{r}
spamCsv_train_dummy <- as_tibble(class2ind(spamCsv_train$yesno)) |> 
  mutate(across(everything(), as.factor)) |>
  add_column(money = spamCsv_train$money)
spamCsv_train_dummy 
```

```{r}
tree_predator <- spamCsv_train_dummy |> 
  rpart(money ~ ., 
        data = _,
        control = rpart.control(minsplit = 2, cp = 0.01))
rpart.plot(tree_predator, roundint = FALSE)
```

```{r}
fit <- spamCsv_train |> 
  train(money ~ ., 
        data = _, 
        method = "rpart",
        control = rpart.control(minsplit = 2),
        tuneGrid = data.frame(cp = 0.01))
fit
```

```{r}
rpart.plot(fit$finalModel)
```

## Class Imbalance

```{r}
library(rpart)
library(rpart.plot)
```

Class distribution

```{r}
ggplot(spamCsv, aes(y = yesno)) + geom_bar()
```

```{r}
spamCsv_yes <- spamCsv |>
  mutate(yesno = factor(spamCsv$yesno == "y",
                       levels = c(TRUE,FALSE),
                       labels = c("Spam","Not_Spam")))
```

```{r}
summary(spamCsv_yes)
```

```{r}
ggplot(spamCsv_yes, aes(y=yesno)) + geom_bar()
```

Creating test and training data. Using a 50/50 split to make sure that the test set has some samples of the rare reptile class.

```{r}
set.seed(1234)
nTrain <- createDataPartition(y = spamCsv_yes$yesno, p = .5, list = FALSE)
training_yes <-spamCsv_yes |> slice(inTrain)
testing_yes <- spamCsv_yes |> slice(-inTrain)
```

## Option 1: Use the Data as is and hope for the best

```{r}
fit <- training_yes |>
  train(yesno~.,
        data= _,
        method = "rpart",
        trControl = trainControl(method = "cv"))
```

```{r}
fit
```

```{r}
rpart.plot(fit$finalModel, extra = 2)
```

```{r}
confusionMatrix(data = predict(fit, testing_yes),
                ref = testing_yes$yesno, positive = "Spam")
```

## Option 2: Balance data with Resampling

```{r}
library(sampling)
set.seed(1000) # for repeatability

id <- strata(training_yes, stratanames = "yesno", size = c(50, 50), method = "srswr")
training_yes_balanced <- training_yes |> 
  slice(id$ID_unit)
table(training_yes_balanced$yesno)
```

```{r}
fit <- training_yes_balanced |> 
  train(yesno ~ .,
        data = _,
        method = "rpart",
        trControl = trainControl(method = "cv"),
        control = rpart.control(minsplit = 5))

fit
```

```{r}
rpart.plot(fit$finalModel, extra = 2)
```

Checking on the unbalanced testing data

```{r}
confusionMatrix(data = predict(fit, testing_yes),
                ref  =testing_yes$yesno, positive = "Spam")
```

```{r}
id <- strata(training_yes, stratanames = "yesno", size = c(50, 100), method = "srswr")
training_yes_balanced <- training_yes |> 
  slice(id$ID_unit)
table(training_yes_balanced$yesno)
```

```{r}
fit <- training_yes_balanced |> 
  train(yesno ~ .,
        data = _,
        method = "rpart",
        trControl = trainControl(method = "cv"),
        control = rpart.control(minsplit = 5))

confusionMatrix(data = predict(fit, testing_yes),
                ref = testing_yes$yesno, positive = "Spam")
```

## Option 3 : Build a larger tree and use Predicted Probabilities

```{r}
fit <- training_yes |> 
  train(yesno ~ .,
        data = _,
        method = "rpart",
        tuneLength = 10,
        trControl = trainControl(method = "cv",
        classProbs = TRUE,  ## necessary for predict with type="prob"
        summaryFunction=twoClassSummary),  ## necessary for ROC
        metric = "ROC",
        control = rpart.control(minsplit = 3))
```

```{r}
fit
```

```{r}
rpart.plot(fit$finalModel, extra = 2)
```

```{r}
confusionMatrix(data = predict(fit, testing_yes),
                ref = testing_yes$yesno, positive = "Spam")
```

```{r}
prob <- predict(fit, testing_yes, type = "prob")
tail(prob)
```

```{r}
pred <- as.factor(ifelse(prob[,"Spam"]>=0.01, "Spam", "Not_Spam"))

confusionMatrix(data = pred,
                ref = testing_yes$yesno, positive = "Spam")
```

## Plot the ROC curve

```{r}
library("pROC")
r <- roc(testing_yes$yesno == "Spam", prob[,"Spam"])
```

```{r}
r
```

```{r}
ggroc(r) + geom_abline(intercept = 1, slope = 1, color = "darkgrey")
```

## Option 4: Use a Cost - Sensitive Classifier

```{r}
cost <- matrix(c(
  0, 1,
  100, 0
), byrow = TRUE, nrow = 2)
cost
```

```{r}
fit <- training_yes |> 
  train(yesno ~ .,
        data = _,
        method = "rpart",
        parms = list(loss = cost),
        trControl = trainControl(method = "cv"))
```

```{r}
fit
```

```{r}
rpart.plot(fit$finalModel, extra = 2)
```

```{r}
confusionMatrix(data = predict(fit, testing_yes),
                ref = testing_yes$yesno, positive = "Spam")
```

# Classification: Alternative Techniques 

## Install packages

```{r}
if(!require(pacman))
  install.packages("pacman")

pacman::p_load(
  C50,                # C5.0 Decision Trees and Rule-Based Models
  caret,              # Classification and Regression Training
  e1071,              # Misc Functions of the Department of Statistics (e1071), TU Wien
  keras,              # R Interface to 'Keras'
  kernlab,            # Kernel-Based Machine Learning Lab
  lattice,            # Trellis Graphics for R
  MASS,               # Support Functions and Datasets for Venables and Ripley's MASS
  mlbench,            # Machine Learning Benchmark Problems
  nnet,               # Feedforward Neural Networks and Multinomial Log-Linear Models
  palmerpenguins,     # Palmer Archipelago (Antarctica) Penguin Data
  party,              # A Laboratory for Recursive Partytioning
  partykit,           # A Toolkit for Recursive Partytioning
  randomForest,       # Breiman and Cutler's Random Forests for Classification and Regression
  rpart,              # Recursive partitioning models
  RWeka,              # R/Weka Interface
  scales,             # Scale Functions for Visualization
  tidymodels,         # Tidy machine learning framework
  tidyverse,          # Tidy data wrangling and visualization
  xgboost             # Extreme Gradient Boosting
)
```

Show fewer Digits

```{r}
options(digits = 3)
```

# Introduction 

## Training and Testing data 

```{r}
# We will use the email spam dataset as used earlier

SpamCsv <- spam
SpamCsv |> glimpse()
```

Multicore support does not work with rJava and RWeka

```{r}
##library(doMC, quietly = TRUE)
##registerDoMC(cores = 4)
##getDoParWorkers()
```

Testing data will not be used to build the model, will be used after building the model. Using 80% for training.

```{r}
set.seed(123) # for reproducibility
inTrain <- createDataPartition(y = SpamCsv$yesno, p=.8)[[1]]
SpamCsv_train <- dplyr::slice(SpamCsv,inTrain)
SpamCsv_test <- dplyr::slice(SpamCsv,-inTrain)
```

## Fitting different Classification Models to the Training Data 

Creating a fixed sampling scheme(10-folds) , so that we can compare the fitted models later.

```{r}
train_index <- createFolds(SpamCsv_train$yesno, k=10)
```

## Conditional Inference tree (Decision Tree)

```{r}
ctreeFit <- SpamCsv |> train (yesno ~ ., 
                              method = "ctree",
                              data =_,
                               tuneLength = 5,
                              trControl = trainControl(method = "cv", indexOut = train_index))

ctreeFit
```

The Plot looks like a mess because there is a lot of features and data involved

```{r}
plot(ctreeFit$finalModel)
```

## C 4.5 Decision Tree

```{r}
C45Fit <- SpamCsv_train |> train(yesno ~.,
                                 method = "J48",
                                 data = _,
                                 tuneLength = 5,
                                 trControl = trainControl(method = "cv", indexOut = train_index))
```

```{r}
C45Fit
```

```{r}
C45Fit$finalModel
```

## K-Nearest Neighbors

```{r}
knnFit <- SpamCsv_train |> train(yesno ~ .,
  method = "knn",
  data = _,
  preProcess = "scale",
    tuneLength = 5,
  tuneGrid=data.frame(k = 1:10),
    trControl = trainControl(method = "cv", indexOut = train_index))
knnFit
```

```{r}
knnFit$finalModel
```

## PART (Rule-based classifier)

```{r}
rulesFit <- SpamCsv_train |> train(yesno ~ .,
  method = "PART",
  data = _,
  tuneLength = 5,
  trControl = trainControl(method = "cv", indexOut = train_index))
rulesFit
```

```{r}
rulesFit$finalModel
```

## Linear Support Vector Machines

```{r}
svmFit <- SpamCsv_train |> train(yesno ~.,
  method = "svmLinear",
  data = _,
    tuneLength = 5,
    trControl = trainControl(method = "cv", indexOut = train_index))
svmFit
```

```{r}
svmFit$finalModel
```

## Random Forest

```{r}
randomForestFit <- SpamCsv_train |> train(yesno ~ .,
  method = "rf",
  data = _,
    tuneLength = 5,
    trControl = trainControl(method = "cv", indexOut = train_index))
randomForestFit
```

```{r}
randomForestFit$finalModel
```

## Gradient Boosted Decision Trees (xgboost)

```{r}
xgboostFit <- SpamCsv_train |> train(yesno ~ .,
  method = "xgbTree",
  data = _,
  tuneLength = 5,
  trControl = trainControl(method = "cv", indexOut = train_index),
  tuneGrid = expand.grid(
    nrounds = 20,
    max_depth = 3,
    colsample_bytree = .6,
    eta = 0.1,
    gamma=0,
    min_child_weight = 1,
    subsample = .5
  ))
xgboostFit
```

```{r}
xgboostFit$finalModel
```

## Artificial Neural Networks

```{r}
nnetFit <- SpamCsv |> train(yesno ~ .,
                            method = "nnet",
                            data = _,
                             tuneLength = 5,
                            trControl = trainControl(method = "cv", indexOut = train_index),trace = FALSE)
nnetFit
```

```{r}
nnetFit$finalModel
```

## Comparing Models

Collecting the performance metrics from the models trained on the same data.

```{r}
resamps <- resamples(list(
  ctree = ctreeFit,
  C45 = C45Fit,
  SVM = svmFit,
  KNN = knnFit,
  rules = rulesFit,
  randomForest = randomForestFit,
  xgboost = xgboostFit,
  NeuralNet = nnetFit
    ))
resamps
```

```{r}
summary(resamps)
```

```{r}
library(lattice)
bwplot(resamps, layout = c(3,1))
```

```{r}
difs <- diff(resamps)
difs 
```

```{r}
summary(difs)
```

## Applying the chosen model to the Test data 

Most of the model do well on the train data, here we choose random forest model, since it has performed better than any other on the train data.

```{r}
pr <- predict(randomForestFit, SpamCsv_test)

pr


```

```{r,warning=FALSE}
confusionMatrix(pr, reference = spamCsv_test$yesno)

```

## Comparing Decision Boundaries of Popular Classification Techniques.

```{r}
library(scales)
library(tidyverse)
library(ggplot2)
library(caret)

decisionplot <- function(model, data, class_var, 
  predict_type = c("class", "prob"), resolution = 3 * 72) {
  # resolution is set to 72 dpi if the image is rendered  3 inches wide. 
  
  y <- data |> pull(class_var)
  x <- data |> dplyr::select(-all_of(class_var))
  
  # resubstitution accuracy
  prediction <- predict(model, x, type = predict_type[1])
  # LDA returns a list
  if(is.list(prediction)) prediction <- prediction$class
  prediction <- factor(prediction, levels = levels(y))
  
  cm <- confusionMatrix(data = prediction, 
                        reference = y)
  acc <- cm$overall["Accuracy"]
  
  # evaluate model on a grid
  r <- sapply(x[, 1:2], range, na.rm = TRUE)
  xs <- seq(r[1,1], r[2,1], length.out = resolution)
  ys <- seq(r[1,2], r[2,2], length.out = resolution)
  g <- cbind(rep(xs, each = resolution), rep(ys, time = resolution))
  colnames(g) <- colnames(r)
  g <- as_tibble(g)
  
  ### guess how to get class labels from predict
  ### (unfortunately not very consistent between models)
  cl <- predict(model, g, type = predict_type[1])
  
  # LDA returns a list
  prob <- NULL
  if(is.list(cl)) { 
    prob <- cl$posterior
    cl <- cl$class
  } else
    if(!is.na(predict_type[2]))
      try(prob <- predict(model, g, type = predict_type[2]))
  
  # we visualize the difference in probability/score between the 
  # winning class and the second best class.
  # don't use probability if predict for the classifier does not support it.
  max_prob <- 1
  if(!is.null(prob))
    try({
      max_prob <- t(apply(prob, MARGIN = 1, sort, decreasing = TRUE))
      max_prob <- max_prob[,1] - max_prob[,2]
    }, silent = TRUE) 
  
  cl <- factor(cl, levels = levels(y))
  
  g <- g |> add_column(prediction = cl, probability = max_prob)
  
  ggplot(g, mapping = aes(
    x = .data[[colnames(g)[1]]], y = .data[[colnames(g)[2]]])) +
    geom_raster(mapping = aes(fill = prediction, alpha = probability)) +
    geom_contour(mapping = aes(z = as.numeric(prediction)), 
      bins = length(levels(cl)), linewidth = .5, color = "black") +
    geom_point(data = data, mapping =  aes(
      x = .data[[colnames(data)[1]]], 
      y = .data[[colnames(data)[2]]],
      shape = .data[[class_var]]), alpha = .7) + 
    scale_alpha_continuous(range = c(0,1), limits = c(0,1), guide = "none") +  
    labs(subtitle = paste("Training accuracy:", round(acc, 2))) +
     theme_minimal(base_size = 14)
}
```

## Using Penguins Dataset 

For easier visualization, we use two dimensions of the penguins dataset. Contour lines visualize the density like mountains on a map

```{r}
set.seed(1000)
data("penguins")
penguins<- as_tibble(penguins) |>
  drop_na()
### Three classes
x<- penguins |> dplyr::select(bill_length_mm,bill_depth_mm,species)
x
```

```{r}
# Using geom_jitter instead of geom_point since there is some overplotting
ggplot(x, aes(x = bill_length_mm, y = bill_depth_mm, fill = species)) +  
  stat_density_2d(geom = "polygon", aes(alpha = after_stat(level))) +
  geom_jitter() +
  theme_minimal(base_size = 14) +
  labs(x = "Bill length (mm)",
       y = "Bill depth (mm)",
       fill = "Species",
       alpha = "Density")
```

## K-Nearest Neighbors Classifier

```{r}
model <- x |> caret::knn3(species ~ ., data= _,k = 1)
decisionplot(model, x, class_var = "species") + 
  labs(title = "kNN (1 neighbor)",
       x = "Bill length (mm)",
       y = "Bill depth (mm)",
       shape = "Species",
       fill = "Prediction")
```

```{r}
model <- x |> caret::knn3(species ~ ., data = _, k = 3)
decisionplot(model, x, class_var = "species") + 
  labs(title = "kNN (3 neighbor)",
       x = "Bill length (mm)",
       y = "Bill depth (mm)",
       shape = "Species",
       fill = "Prediction")
```

```{r}
model <- x |> caret::knn3(species ~ ., data = _, k = 9)
decisionplot(model, x, class_var = "species") + 
  labs(title = "kNN (9 neighbor)",
       x = "Bill length (mm)",
       y = "Bill depth (mm)",
       shape = "Species",
       fill = "Prediction")
```

## Naive bayes Classifier

```{r}
model <- x |> e1071::naiveBayes(species ~ ., data = _)
decisionplot(model, x, class_var = "species", 
             predict_type = c("class", "raw")) + 
  labs(title = "Naive Bayes",
       x = "Bill length (mm)",
       y = "Bill depth (mm)",
       shape = "Species",
       fill = "Prediction") 
```

## Linear Discriminant Analysis

```{r}
model <- x |> MASS::lda(species ~ ., data = _)
decisionplot(model, x, class_var = "species") + 
  labs(title = "LDA",
       x = "Bill length (mm)",
       y = "Bill depth (mm)",
       shape = "Species",
       fill = "Prediction")
```

## Multinomial Logistic Regression

```{r}
model <- x |> nnet::multinom(species ~., data = _)
```

```{r}
decisionplot(model, x, class_var = "species") + 
  labs(title = "Multinomial Logistic Regression",
       x = "Bill length (mm)",
       y = "Bill depth (mm)",
       shape = "Species",
       fill = "Prediction")


```

## Decision trees

```{r}
model <- x |> rpart::rpart(species ~ ., data = _)
decisionplot(model, x, class_var = "species") + 
  labs(title = "CART",
       x = "Bill length (mm)",
       y = "Bill depth (mm)",
       shape = "Species",
       fill = "Prediction")
```

```{r}
model <- x |> rpart::rpart(species ~ ., data = _,
  control = rpart.control(cp = 0.001, minsplit = 1))
decisionplot(model, x, class_var = "species") + 
  labs(title = "CART (overfitting)",
       x = "Bill length (mm)",
       y = "Bill depth (mm)",
       shape = "Species",
       fill = "Prediction")
```

```{r}
model <- x |> C50::C5.0(species ~ ., data = _)
decisionplot(model, x, class_var = "species") + 
  labs(title = "C5.0",
       x = "Bill length (mm)",
       y = "Bill depth (mm)",
       shape = "Species",
       fill = "Prediction")
```

## Random Forest 

```{r}
model <- x |> randomForest::randomForest(species ~ ., data = _)
decisionplot(model, x, class_var = "species") + 
  labs(title = "Random Forest",
       x = "Bill length (mm)",
       y = "Bill depth (mm)",
       shape = "Species",
       fill = "Prediction")
```

## SVM

```{r}
model <- x |> e1071::svm(species ~ ., data = _, kernel = "linear")
decisionplot(model, x, class_var = "species") + 
  labs(title = "SVM (linear kernel)",
       x = "Bill length (mm)",
       y = "Bill depth (mm)",
       shape = "Species",
       fill = "Prediction")
```

```{r}
model <- x |> e1071::svm(species ~ ., data = _, kernel = "radial")
decisionplot(model, x, class_var = "species") + 
  labs(title = "SVM (radial kernel)",
       x = "Bill length (mm)",
       y = "Bill depth (mm)",
       shape = "Species",
       fill = "Prediction")
```

```{r}
model <- x |> e1071::svm(species ~ ., data = _, kernel = "polynomial")
decisionplot(model, x, class_var = "species") + 
  labs(title = "SVM (polynomial kernel)",
       x = "Bill length (mm)",
       y = "Bill depth (mm)",
       shape = "Species",
       fill = "Prediction")
```

```{r}
model <- x |> e1071::svm(species ~ ., data = _, kernel = "sigmoid")
decisionplot(model, x, class_var = "species") + 
  labs(title = "SVM (sigmoid kernel)",
       x = "Bill length (mm)",
       y = "Bill depth (mm)",
       shape = "Species",
       fill = "Prediction")
```

## Single Layered Feed Forward Neural Network

```{r}
model <-x |> nnet::nnet(species ~ ., data = _, size = 1, trace = FALSE)
decisionplot(model, x, class_var  = "species", 
  predict_type = c("class", "raw")) + 
  labs(title = "NN (1 neuron)",
       x = "Bill length (mm)",
       y = "Bill depth (mm)",
       shape = "Species",
       fill = "Prediction")
```

```{r}
model <-x |> nnet::nnet(species ~ ., data = _, size = 2, trace = FALSE)
decisionplot(model, x, class_var  = "species", 
  predict_type = c("class", "raw")) + 
  labs(title = "NN (2 neurons)",
       x = "Bill length (mm)",
       y = "Bill depth (mm)",
       shape = "Species",
       fill = "Prediction")
```

```{r}
model <-x |> nnet::nnet(species ~ ., data = _, size = 4, trace = FALSE)
decisionplot(model, x, class_var  = "species", 
  predict_type = c("class", "raw")) + 
  labs(title = "NN (4 neurons)",
       x = "Bill length (mm)",
       y = "Bill depth (mm)",
       shape = "Species",
       fill = "Prediction")
```

```{r}
model <-x |> nnet::nnet(species ~ ., data = _, size = 10, trace = FALSE)
decisionplot(model, x, class_var  = "species", 
  predict_type = c("class", "raw")) + 
  labs(title = "NN (10 neurons)",
       x = "Bill length (mm)",
       y = "Bill depth (mm)",
       shape = "Species",
       fill = "Prediction")
```

## Circle Dataset

This dataset is not linearly seperable

```{r}
set.seed(1000)

x <- mlbench::mlbench.circle(500)
###x <- mlbench::mlbench.cassini(500)
###x <- mlbench::mlbench.spirals(500, sd = .1)
###x <- mlbench::mlbench.smiley(500)
x <- cbind(as.data.frame(x$x), factor(x$classes))
colnames(x) <- c("x", "y", "class")
x <- as_tibble(x)
x
```

```{r}
ggplot(x, aes(x = x, y = y, color = class)) + 
  geom_point() +
  theme_minimal(base_size = 14)
```

## K-Nearest Classifier

```{r}
model <- x |> caret::knn3(class ~ ., data = _, k = 1)
decisionplot(model, x, class_var = "class") + 
  labs(title = "kNN (1 neighbor)",
       shape = "Class",
       fill = "Prediction")
```

```{r}
model <- x |> caret::knn3(class ~ ., data = _, k = 10)
decisionplot(model, x, class_var = "class") + 
  labs(title = "kNN (10 neighbor)",
       shape = "Class",
       fill = "Prediction")
```

## Naive Bayes Classifier

```{r}
model <- x |> e1071::naiveBayes(class ~ ., data = _)
decisionplot(model, x, class_var = "class", 
  predict_type = c("class", "raw")) + 
  labs(title = "naive Bayes",
       shape = "Class",
       fill = "Prediction")
```

## Linear Discriminant Analysis (LDA)

```{r}
model <- x |> MASS::lda(class ~ ., data = _)
decisionplot(model, x, class_var = "class") + 
  labs(title = "LDA",
       shape = "Class",
       fill = "Prediction")
```

## Logistic Regression

Multinomial logistic regression is an extension of logistic regression to problems with more than two classes. It also tries to find a linear decision boundary.

```{r}
model <- x |> nnet::multinom(class ~., data = _)
decisionplot(model, x, class_var = "class") + 
  labs(title = "Multinomial Logistic Regression",
       shape = "Class",
       fill = "Prediction")
```

## Decision Trees

```{r}
model <- x |> rpart::rpart(class ~ ., data = _)
decisionplot(model, x, class_var = "class") + 
  labs(title = "CART",
       shape = "Class",
       fill = "Prediction")
```

```{r}
model <- x |> rpart::rpart(class ~ ., data = _,
  control = rpart.control(cp = 0.001, minsplit = 1))
decisionplot(model, x, class_var = "class") + 
  labs(title = "CART (overfitting)",
       shape = "Class",
       fill = "Prediction")
```

```{r}
model <- x |> C50::C5.0(class ~ ., data = _)
decisionplot(model, x, class_var = "class") + 
  labs(title = "C5.0",
       shape = "Class",
       fill = "Prediction")
```

## Random Forest

```{r}
library(randomForest)
model <- x |> randomForest(class ~ ., data = _)
decisionplot(model, x, class_var = "class") + 
  labs(title = "Random Forest",
       shape = "Class",
       fill = "Prediction")
```

## SVM 

```{r}
model <- x |> e1071::svm(class ~ ., data = _, kernel = "linear")
decisionplot(model, x, class_var = "class") + 
  labs(title = "SVM (linear kernel)",
       shape = "Class",
       fill = "Prediction")
```

```{r}
model <- x |> e1071::svm(class ~ ., data = _, kernel = "radial")
decisionplot(model, x, class_var = "class") + 
  labs(title = "SVM (radial kernel)",
       shape = "Class",
       fill = "Prediction")
```

```{r}
model <- x |> e1071::svm(class ~ ., data = _, kernel = "polynomial")
decisionplot(model, x, class_var = "class") + 
  labs(title = "SVM (polynomial kernel)",
       shape = "Class",
       fill = "Prediction")
```

```{r}
model <- x |> e1071::svm(class ~ ., data = _, kernel = "sigmoid")
decisionplot(model, x, class_var = "class") + 
  labs(title = "SVM (sigmoid kernel)",
       shape = "Class",
       fill = "Prediction")
```

## Single Layered Feed Forward Neural Network

```{r}
model <-x |> nnet::nnet(class ~ ., data = _, size = 1, trace = FALSE)
decisionplot(model, x, class_var = "class", 
  predict_type = c("class")) + 
  labs(title = "NN (1 neuron)",
       shape = "Class",
       fill = "Prediction")
```

```{r}
model <-x |> nnet::nnet(class ~ ., data = _, size = 2, trace = FALSE)
decisionplot(model, x, class_var = "class", 
  predict_type = c("class")) + 
  labs(title = "NN (2 neurons)",
       shape = "Class",
       fill = "Prediction")
```

```{r}
model <-x |> nnet::nnet(class ~ ., data = _, size = 4, trace = FALSE)
decisionplot(model, x, class_var = "class", 
  predict_type = c("class")) + 
  labs(title = "NN (4 neurons)",
       shape = "Class",
       fill = "Prediction")
```

```{r}
model <-x |> nnet::nnet(class ~ ., data = _, size = 10, trace = FALSE)
decisionplot(model, x, class_var = "class", 
  predict_type = c("class")) + 
  labs(title = "NN (10 neurons)",
       shape = "Class",
       fill = "Prediction")
```
